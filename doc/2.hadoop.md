# 1. hadoop四大模块

```shell
common: 公共模块(支持hadoop其他模块的公共工具, 包括hdfs、rpc和序列化库api)
HDFS: 存储数据, 为访问应用数据提供高吞吐量的分布式文件系统
YARN: 资源管理, 一个全局的工作调度与资源分配
MapReduce: 基于yarn的大数据分布式并行计算模型
```



# 2. hadoop的安装模式

```shell
单机模式: 所有的程序都在单个jvm运行(测试用)
伪分布式: 所有的守护进程都在一台机器上
完全分布式: HA
```



# 3. 安装hadoop

##### 1.创建目录

```shell
#创建目录
mkdir -p /opt/modules
cd /opt/modules
mkdir apache cdh
#创建安装软件目录
mkdir /opt/software
```

##### 2. 配置jdk环境变量及主机名、ssh免密等

```shell
vi /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_152
export PATH=JAVA_HOME/bin:$PATH
source /etc/profile
jps
# 修改主机名, 将主机名改为hiyacg.com
vi /etc/hostname
# 修改hosts, 添加192.168.0.208 hiyacg.com
vi /etc/hosts
# ssh免密
ssh-keygen -t rsa
ssh-copy-id hiyacg.com
# 操作完成后查看authorized_keys文件
ls -a ~/.ssh
ssh hiyacg.com
# 安装tree(tree命令查看目录结构)
yum install -y tree

tree data
data
└── hadoop_tmp

1 directory, 0 files
```

##### 3.下载hadoop并解压

```shell
http://archive.cloudera.com/cdh5/cdh/5/
wget http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.9.3.tar.gz
tar -zxvf hadoop-2.6.0-cdh5.9.3.tar.gz
mv /opt/software/hadoop-2.6.0-cdh5.9.3 /opt/modules/cdh/

#配置hadoop环境变量
vi /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_152
export HADOOP_HOME=/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3
export PATH=JAVA_HOME/bin:$HADOOP_HOME/bin:$PATH
source /etc/profile
```

##### 4. 修改3个env配置

```shell
#/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/etc/hadoop
#修改3个env文件中的JAVA_HOME
#hadoop-env.sh
#mapred-env.sh
#yarn-env.sh
export JAVA_HOME=/usr/java/jdk1.8.0_152
```

##### 5.配置hdfs相关

```shell
#/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/etc/hadoop
#1.修改core-site.xml
#namecode访问入口
<configuration>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://hiyacg.com:8020</value>
    </property>
    <property>
		<name>hadoop.tmp.dir</name>
		<value>/opt/modules/data/hadoop_tmp</value>
    </property>
</configuration>

#2.修改hdfs-site.xml
#副本数配置为1, 默认值为3
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
    </property>
    <property>
		<name>dfs.permissions</name>
		<value>true</value>
    </property>
    <property>
		<name>dfs.namenode.secondary.http-address</name>
		<value>hiyacg.com:50090</value>
    </property>
</configuration>


#3.修改slaves中的主机名
vi slaves
hiyacg.com

#4.格式化(不能执行多次)
/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/bin/hadoop namenode -format
#启动namenode
/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/sbin/hadoop-daemon.sh start namenode
#启动datanode
/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/sbin/hadoop-daemon.sh start datanode
#启动secondarynamenode
/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/sbin/hadoop-daemon.sh start secondarynamenode
#停止namenode
/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/sbin/hadoop-daemon.sh stop namenode
#停止datanode
/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/sbin/hadoop-daemon.sh stop datanode
#停止secondarynamenode
/opt/modules/cdh/hadoop-2.6.0-cdh5.9.3/sbin/hadoop-daemon.sh stop secondarynamenode

jps

#命令上传文件
bin/hdfs dfs -put bin/test.txt /

#web访问
http://192.168.0.208:50070

```

##### 5.1命令上传文件

```shell
bin/hdfs dfs -put ./test.txt /demo
```

##### 5.2错误处理

```shell
bin/hdfs dfs -put ./test.txt /demo
19/06/30 23:43:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
```

##### 5.3需要手动下载hadoop-native-64-2.6.0.tar(经测试该方法无效,后续处理)

```shell
下载地址: http://dl.bintray.com/sequenceiq/sequenceiq-bin/
下载hadoop-native-64-2.6.0.tar文件放在$HADOOP_HOME/lib/native

```



##### 6.NameNode

```shell
NameNode是主节点, 存储文件的元数据如文件名、文件目录结构、文件属性(生成时间、副本数、文件权限)、以及每个文件的块列表和块所在的DataNode等
```

##### 7.DataNode

```shell
DataNode在本地文件系统存储块数据,以及块数据的校验和
1.hdfs最小存储单位128m
2.如果一个文件的大小小于块的大小, 不会占据整个块的空间
3.小于最小存储单位的多个文件不能放在同一块中
4.存储文件,文件被分成block存储在磁盘中, 为了数据安全, 文件会有多个副本, 放置到不同的机器上
5.namenode和client的指令进行存储或者检索block, 并周期性的向namenode发送报告(心跳机制)
```

##### 8.Secondary NameNode

```shell
用来监控HDFS状态的辅助后台程序, 每隔一段时间获取HDFS元数据的快照
fsimage:记录
```



